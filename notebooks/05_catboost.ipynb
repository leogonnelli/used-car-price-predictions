{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb5f841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. Imports ===\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from catboost import Pool\n",
    "import joblib\n",
    "\n",
    "from src.load_data import load_train_data, save_processed_data, load_test_data\n",
    "from src.preprocess.preprocessing_pipeline import PreprocessingPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9611aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. Load data ===\n",
    "df = load_train_data()\n",
    "\n",
    "# === 3. Prepare features and target (before preprocessing) ===\n",
    "X_raw = df.drop(columns=[\"price\"])\n",
    "y_raw = df[\"price\"]\n",
    "\n",
    "# === 4. Train-test split (on raw data) ===\n",
    "X_train_raw, X_val_raw, y_train_raw, y_val_raw = train_test_split(\n",
    "    X_raw, y_raw, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb74fc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (19748, 14)\n",
      "X_train sample columns: ['model', 'transmission', 'mileage', 'fuelType', 'tax', 'mpg', 'engineSize', 'brand', 'car_age', 'mileage_per_year', 'engine_efficiency', 'power_index', 'age_mileage_interaction', 'log_mileage']\n",
      "y_train description:\n",
      " count    19748.000000\n",
      "mean         9.838892\n",
      "std          0.463652\n",
      "min          6.478510\n",
      "25%          9.546241\n",
      "50%          9.862718\n",
      "75%         10.146277\n",
      "max         11.918051\n",
      "Name: log_price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# === 4a. Preprocess training data ===\n",
    "train_df = X_train_raw.copy()\n",
    "train_df[\"price\"] = y_train_raw\n",
    "\n",
    "pipeline = PreprocessingPipeline(\n",
    "    use_log_target=True,\n",
    "    drop_low_importance=True,\n",
    "    encode_data=False  # CatBoost handles categoricals natively\n",
    ")\n",
    "train_processed = pipeline.fit_transform(train_df)\n",
    "\n",
    "# Ensure categorical columns are strings\n",
    "cat_features = [\"model\", \"brand\", \"transmission\", \"fuelType\"]\n",
    "for col in cat_features:\n",
    "    if col in train_processed.columns:\n",
    "        train_processed[col] = train_processed[col].astype(str)\n",
    "\n",
    "X_train = train_processed.drop(columns=[\"price\", \"log_price\"], errors='ignore')\n",
    "y_train = train_processed[\"log_price\"]\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_train sample columns:\", X_train.columns.tolist())\n",
    "print(\"y_train description:\\n\", y_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f43e008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4b. Preprocess validation data (using fitted pipeline) ===\n",
    "val_df = X_val_raw.copy()\n",
    "val_df[\"price\"] = y_val_raw\n",
    "val_processed = pipeline.transform(val_df)\n",
    "\n",
    "for col in cat_features:\n",
    "    if col in val_processed.columns:\n",
    "        val_processed[col] = val_processed[col].astype(str)\n",
    "\n",
    "X_val = val_processed.drop(columns=[\"price\", \"log_price\"], errors='ignore')\n",
    "y_val = val_processed[\"log_price\"] if \"log_price\" in val_processed.columns else y_val_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac8e8995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "[CV 1/3] END depth=6, iterations=500, learning_rate=0.03;, score=-0.109 total time=   1.3s\n",
      "[CV 2/3] END depth=6, iterations=500, learning_rate=0.03;, score=-0.112 total time=   1.2s\n",
      "[CV 3/3] END depth=6, iterations=500, learning_rate=0.03;, score=-0.114 total time=   1.1s\n",
      "[CV 1/3] END depth=6, iterations=500, learning_rate=0.05;, score=-0.103 total time=   1.2s\n",
      "[CV 2/3] END depth=6, iterations=500, learning_rate=0.05;, score=-0.106 total time=   1.1s\n",
      "[CV 3/3] END depth=6, iterations=500, learning_rate=0.05;, score=-0.108 total time=   1.2s\n",
      "[CV 1/3] END depth=6, iterations=500, learning_rate=0.1;, score=-0.098 total time=   1.2s\n",
      "[CV 2/3] END depth=6, iterations=500, learning_rate=0.1;, score=-0.101 total time=   1.2s\n",
      "[CV 3/3] END depth=6, iterations=500, learning_rate=0.1;, score=-0.104 total time=   1.2s\n",
      "[CV 1/3] END depth=6, iterations=1000, learning_rate=0.03;, score=-0.101 total time=   2.3s\n",
      "[CV 2/3] END depth=6, iterations=1000, learning_rate=0.03;, score=-0.104 total time=   2.3s\n",
      "[CV 3/3] END depth=6, iterations=1000, learning_rate=0.03;, score=-0.106 total time=   2.2s\n",
      "[CV 1/3] END depth=6, iterations=1000, learning_rate=0.05;, score=-0.097 total time=   2.4s\n",
      "[CV 2/3] END depth=6, iterations=1000, learning_rate=0.05;, score=-0.100 total time=   2.2s\n",
      "[CV 3/3] END depth=6, iterations=1000, learning_rate=0.05;, score=-0.103 total time=   3.0s\n",
      "[CV 1/3] END depth=6, iterations=1000, learning_rate=0.1;, score=-0.095 total time=   2.7s\n",
      "[CV 2/3] END depth=6, iterations=1000, learning_rate=0.1;, score=-0.098 total time=   2.6s\n",
      "[CV 3/3] END depth=6, iterations=1000, learning_rate=0.1;, score=-0.101 total time=   2.4s\n",
      "[CV 1/3] END depth=8, iterations=500, learning_rate=0.03;, score=-0.103 total time=   1.9s\n",
      "[CV 2/3] END depth=8, iterations=500, learning_rate=0.03;, score=-0.106 total time=   1.9s\n",
      "[CV 3/3] END depth=8, iterations=500, learning_rate=0.03;, score=-0.108 total time=   1.9s\n",
      "[CV 1/3] END depth=8, iterations=500, learning_rate=0.05;, score=-0.100 total time=   2.0s\n",
      "[CV 2/3] END depth=8, iterations=500, learning_rate=0.05;, score=-0.102 total time=   2.0s\n",
      "[CV 3/3] END depth=8, iterations=500, learning_rate=0.05;, score=-0.105 total time=   2.0s\n",
      "[CV 1/3] END depth=8, iterations=500, learning_rate=0.1;, score=-0.095 total time=   2.3s\n",
      "[CV 2/3] END depth=8, iterations=500, learning_rate=0.1;, score=-0.099 total time=   2.1s\n",
      "[CV 3/3] END depth=8, iterations=500, learning_rate=0.1;, score=-0.102 total time=   2.0s\n",
      "[CV 1/3] END depth=8, iterations=1000, learning_rate=0.03;, score=-0.098 total time=   3.9s\n",
      "[CV 2/3] END depth=8, iterations=1000, learning_rate=0.03;, score=-0.100 total time=   4.3s\n",
      "[CV 3/3] END depth=8, iterations=1000, learning_rate=0.03;, score=-0.103 total time=   4.3s\n",
      "[CV 1/3] END depth=8, iterations=1000, learning_rate=0.05;, score=-0.095 total time=   4.0s\n",
      "[CV 2/3] END depth=8, iterations=1000, learning_rate=0.05;, score=-0.099 total time=   4.0s\n",
      "[CV 3/3] END depth=8, iterations=1000, learning_rate=0.05;, score=-0.101 total time=   4.1s\n",
      "[CV 1/3] END depth=8, iterations=1000, learning_rate=0.1;, score=-0.094 total time=   3.9s\n",
      "[CV 2/3] END depth=8, iterations=1000, learning_rate=0.1;, score=-0.097 total time=   4.1s\n",
      "[CV 3/3] END depth=8, iterations=1000, learning_rate=0.1;, score=-0.100 total time=   3.9s\n",
      "[CV 1/3] END depth=10, iterations=500, learning_rate=0.03;, score=-0.101 total time=   3.6s\n",
      "[CV 2/3] END depth=10, iterations=500, learning_rate=0.03;, score=-0.105 total time=   3.4s\n",
      "[CV 3/3] END depth=10, iterations=500, learning_rate=0.03;, score=-0.106 total time=   3.3s\n",
      "[CV 1/3] END depth=10, iterations=500, learning_rate=0.05;, score=-0.099 total time=   3.7s\n",
      "[CV 2/3] END depth=10, iterations=500, learning_rate=0.05;, score=-0.101 total time=   3.4s\n",
      "[CV 3/3] END depth=10, iterations=500, learning_rate=0.05;, score=-0.103 total time=   3.8s\n",
      "[CV 1/3] END depth=10, iterations=500, learning_rate=0.1;, score=-0.097 total time=   3.3s\n",
      "[CV 2/3] END depth=10, iterations=500, learning_rate=0.1;, score=-0.100 total time=   3.2s\n",
      "[CV 3/3] END depth=10, iterations=500, learning_rate=0.1;, score=-0.102 total time=   3.3s\n",
      "[CV 1/3] END depth=10, iterations=1000, learning_rate=0.03;, score=-0.097 total time=   6.3s\n",
      "[CV 2/3] END depth=10, iterations=1000, learning_rate=0.03;, score=-0.100 total time=   6.4s\n",
      "[CV 3/3] END depth=10, iterations=1000, learning_rate=0.03;, score=-0.102 total time=   6.4s\n",
      "[CV 1/3] END depth=10, iterations=1000, learning_rate=0.05;, score=-0.096 total time=   6.7s\n",
      "[CV 2/3] END depth=10, iterations=1000, learning_rate=0.05;, score=-0.098 total time=   6.5s\n",
      "[CV 3/3] END depth=10, iterations=1000, learning_rate=0.05;, score=-0.100 total time=   6.4s\n",
      "[CV 1/3] END depth=10, iterations=1000, learning_rate=0.1;, score=-0.096 total time=   7.1s\n",
      "[CV 2/3] END depth=10, iterations=1000, learning_rate=0.1;, score=-0.099 total time=   7.6s\n",
      "[CV 3/3] END depth=10, iterations=1000, learning_rate=0.1;, score=-0.101 total time=   6.9s\n",
      "Best parameters: {'depth': 8, 'iterations': 1000, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# === 5. Hyperparameter tuning ===\n",
    "# Define parameter grid for tuning\n",
    "param_grid = {\n",
    "    'depth': [6, 8, 10],\n",
    "    'learning_rate': [0.03, 0.05, 0.1],\n",
    "    'iterations': [500, 1000]\n",
    "}\n",
    "\n",
    "cat_feature_indices = [X_train.columns.get_loc(col) for col in cat_features if col in X_train.columns]\n",
    "\n",
    "cat_model = CatBoostRegressor(verbose=0, random_state=42, cat_features=cat_feature_indices)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=cat_model, param_grid=param_grid, cv=3, scoring='neg_root_mean_squared_error', verbose=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "cat_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18db8aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions range: 7.608216132873414 to 11.672617062798953\n",
      "Validation RMSE (log scale): 0.09557646862363758\n",
      "Validation RMSE ($): 1952.9618702506903\n"
     ]
    }
   ],
   "source": [
    "# === 6. Evaluate performance ===\n",
    "val_preds = cat_model.predict(X_val)\n",
    "\n",
    "print(\"Validation predictions range:\", val_preds.min(), \"to\", val_preds.max())\n",
    "rmse = root_mean_squared_error(y_val, val_preds)\n",
    "print(f\"Validation RMSE (log scale): {rmse}\")\n",
    "print(f\"Validation RMSE ($): {root_mean_squared_error(np.expm1(y_val), np.expm1(val_preds))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed3f2874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CatBoost model to: ../models/catboost_model.joblib\n"
     ]
    }
   ],
   "source": [
    "# === 7. Save model ===\n",
    "model_path = \"../models/catboost_model.joblib\"\n",
    "joblib.dump(cat_model, model_path)\n",
    "print(f\"Saved CatBoost model to: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9796a7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CatBoost predictions to: ../results/catboost_test_preds.csv\n"
     ]
    }
   ],
   "source": [
    "# === 8. Predict on test set ===\n",
    "test_df = load_test_data()\n",
    "# Use the same pipeline that was fitted on training data\n",
    "test_clean = pipeline.transform(test_df)\n",
    "\n",
    "for col in cat_features:\n",
    "    if col in test_clean.columns:\n",
    "        test_clean[col] = test_clean[col].astype(str)\n",
    "\n",
    "# Ensure test columns match training set\n",
    "test_clean = test_clean[X_train.columns]\n",
    "\n",
    "test_preds_log = cat_model.predict(test_clean)\n",
    "\n",
    "# === 9. Convert back to original scale and save ===\n",
    "test_preds = np.expm1(test_preds_log)\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": test_df[\"ID\"],\n",
    "    \"Actual\": test_preds\n",
    "})\n",
    "\n",
    "submission_path = \"../results/catboost_test_preds.csv\"\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"Saved CatBoost predictions to: {submission_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
