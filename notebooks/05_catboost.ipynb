{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. Imports ===\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "# Reload modules to pick up latest changes\n",
    "import importlib\n",
    "import src.preprocess.preprocessing_pipeline\n",
    "import src.preprocess.encoding\n",
    "import src.preprocess.feature_engineering\n",
    "importlib.reload(src.preprocess.encoding)\n",
    "importlib.reload(src.preprocess.feature_engineering)\n",
    "importlib.reload(src.preprocess.preprocessing_pipeline)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import Pool\n",
    "import joblib\n",
    "\n",
    "from src.load_data import load_train_data, save_processed_data, load_test_data\n",
    "from src.preprocess.preprocessing_pipeline import PreprocessingPipeline\n",
    "\n",
    "print(\"✅ Modules reloaded - ready to use new features!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. Load data ===\n",
    "df = load_train_data()\n",
    "\n",
    "# === 3. Prepare features and target (before preprocessing) ===\n",
    "X_raw = df.drop(columns=[\"price\"])\n",
    "y_raw = df[\"price\"]\n",
    "\n",
    "# === 4. Train-test split (on raw data) ===\n",
    "X_train_raw, X_val_raw, y_train_raw, y_val_raw = train_test_split(\n",
    "    X_raw, y_raw, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4a. Preprocess training data ===\n",
    "train_df = X_train_raw.copy()\n",
    "train_df[\"price\"] = y_train_raw\n",
    "\n",
    "pipeline = PreprocessingPipeline(\n",
    "    use_log_target=True,\n",
    "    drop_low_importance=True,\n",
    "    encode_data=False,  # CatBoost handles categoricals natively\n",
    "    use_target_encoding=True  # Add target encoding as additional features\n",
    ")\n",
    "train_processed = pipeline.fit_transform(train_df)\n",
    "\n",
    "# Ensure categorical columns are strings\n",
    "cat_features = [\"model\", \"brand\", \"transmission\", \"fuelType\", \"brand_model\"]\n",
    "for col in cat_features:\n",
    "    if col in train_processed.columns:\n",
    "        train_processed[col] = train_processed[col].astype(str)\n",
    "\n",
    "X_train = train_processed.drop(columns=[\"price\", \"log_price\"], errors='ignore')\n",
    "y_train = train_processed[\"log_price\"]\n",
    "\n",
    "print(\"✅ X_train shape:\", X_train.shape)\n",
    "print(\"✅ Categorical features (for native handling):\", cat_features)\n",
    "print(\"✅ Target-encoded features:\", [col for col in X_train.columns if 'target_enc' in col])\n",
    "print(\"✅ Tax features:\", [col for col in X_train.columns if 'tax' in col.lower()])\n",
    "print(\"✅ Polynomial features:\", [col for col in X_train.columns if 'squared' in col or 'interaction' in col])\n",
    "print(\"\\nX_train sample columns:\", X_train.columns.tolist()[:10], \"...\")\n",
    "print(\"y_train description:\\n\", y_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4b. Preprocess validation data (using fitted pipeline) ===\n",
    "val_df = X_val_raw.copy()\n",
    "val_df[\"price\"] = y_val_raw\n",
    "val_processed = pipeline.transform(val_df)\n",
    "\n",
    "# Ensure categorical columns are strings (same list as training)\n",
    "cat_features = [\"model\", \"brand\", \"transmission\", \"fuelType\", \"brand_model\"]\n",
    "for col in cat_features:\n",
    "    if col in val_processed.columns:\n",
    "        val_processed[col] = val_processed[col].astype(str)\n",
    "\n",
    "X_val = val_processed.drop(columns=[\"price\", \"log_price\"], errors='ignore')\n",
    "y_val = val_processed[\"log_price\"] if \"log_price\" in val_processed.columns else y_val_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 5. Hyperparameter tuning - Best Generalization Approach ===\n",
    "# Strategy: Start from known good config (depth=8, lr=0.1, iterations=1000, RMSE ~2023)\n",
    "# Only tune regularization (l2_leaf_reg) to prevent overfitting\n",
    "# This minimizes hyperparameter space and reduces overfitting risk\n",
    "\n",
    "# Define categorical features (must match what was used in preprocessing)\n",
    "cat_features = [\"model\", \"brand\", \"transmission\", \"fuelType\", \"brand_model\"]\n",
    "cat_feature_indices = [X_train.columns.get_loc(col) for col in cat_features if col in X_train.columns]\n",
    "\n",
    "# Test different regularization values with known good base config\n",
    "l2_values = [1, 3, 5, 7, 10]\n",
    "best_val_rmse = float('inf')\n",
    "best_l2 = None\n",
    "best_model = None\n",
    "\n",
    "print(\"Testing regularization values with base config:\")\n",
    "print(\"Base: depth=8, learning_rate=0.1, iterations=1000\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for l2 in l2_values:\n",
    "    model = CatBoostRegressor(\n",
    "        depth=8,\n",
    "        learning_rate=0.1,\n",
    "        iterations=1000,\n",
    "        l2_leaf_reg=l2,\n",
    "        verbose=0,\n",
    "        random_state=42,\n",
    "        cat_features=cat_feature_indices,\n",
    "        loss_function='RMSE'\n",
    "    )\n",
    "    \n",
    "    # Train on training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate on holdout validation set (better for generalization than CV)\n",
    "    val_preds = model.predict(X_val)\n",
    "    val_rmse = root_mean_squared_error(y_val, val_preds)\n",
    "    val_rmse_raw = root_mean_squared_error(np.expm1(y_val), np.expm1(val_preds))\n",
    "    \n",
    "    print(f\"l2_leaf_reg={l2:2d}: Val RMSE (log)={val_rmse:.5f}, Val RMSE ($)={val_rmse_raw:.2f}\")\n",
    "    \n",
    "    if val_rmse < best_val_rmse:\n",
    "        best_val_rmse = val_rmse\n",
    "        best_l2 = l2\n",
    "        best_model = model\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"\\n✅ Best regularization: l2_leaf_reg={best_l2}\")\n",
    "print(f\"Best validation RMSE (log scale): {best_val_rmse:.5f}\")\n",
    "print(f\"Best validation RMSE ($): {root_mean_squared_error(np.expm1(y_val), np.expm1(best_model.predict(X_val))):.2f}\")\n",
    "\n",
    "cat_model = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6. Evaluate performance ===\n",
    "val_preds = cat_model.predict(X_val)\n",
    "\n",
    "print(\"Validation predictions range:\", val_preds.min(), \"to\", val_preds.max())\n",
    "rmse_log = root_mean_squared_error(y_val, val_preds)\n",
    "rmse_raw = root_mean_squared_error(np.expm1(y_val), np.expm1(val_preds))\n",
    "print(f\"Validation RMSE (log scale): {rmse_log:.5f}\")\n",
    "print(f\"Validation RMSE ($): {rmse_raw:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 7. Save model ===\n",
    "model_path = \"../models/catboost_model.joblib\"\n",
    "joblib.dump(cat_model, model_path)\n",
    "print(f\"Saved CatBoost model to: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 8. Predict on test set ===\n",
    "test_df = load_test_data()\n",
    "# Use the same pipeline that was fitted on training data\n",
    "test_clean = pipeline.transform(test_df)\n",
    "\n",
    "# Ensure categorical columns are strings (same list as training)\n",
    "cat_features = [\"model\", \"brand\", \"transmission\", \"fuelType\", \"brand_model\"]\n",
    "for col in cat_features:\n",
    "    if col in test_clean.columns:\n",
    "        test_clean[col] = test_clean[col].astype(str)\n",
    "\n",
    "# Ensure test columns match training set\n",
    "test_clean = test_clean[X_train.columns]\n",
    "\n",
    "test_preds_log = cat_model.predict(test_clean)\n",
    "\n",
    "# === 9. Convert back to original scale and save ===\n",
    "test_preds = np.expm1(test_preds_log)\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": test_df[\"ID\"],\n",
    "    \"Actual\": test_preds\n",
    "})\n",
    "\n",
    "submission_path = \"../results/catboost_test_preds.csv\"\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"Saved CatBoost predictions to: {submission_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
