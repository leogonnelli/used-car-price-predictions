{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === XGBoost Modeling Notebook ===\n",
    "\n",
    "# === 1. Imports ===\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../\"))  # ensure src/ is importable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "\n",
    "from src.load_data import load_train_data, load_test_data\n",
    "from src.preprocess.preprocessing_pipeline import PreprocessingPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. Load data ===\n",
    "df = load_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3. Prepare features and target (before preprocessing) ===\n",
    "X_raw = df.drop(columns=[\"price\"])\n",
    "y_raw = df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4. Train-test split (on raw data) ===\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(\n",
    "    X_raw, y_raw, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4a. Preprocess training data ===\n",
    "train_df = X_train_raw.copy()\n",
    "train_df[\"price\"] = y_train_raw\n",
    "\n",
    "pipeline = PreprocessingPipeline(\n",
    "    use_log_target=True,\n",
    "    drop_low_importance=True,\n",
    "    encode_data=True\n",
    ")\n",
    "train_processed = pipeline.fit_transform(train_df)\n",
    "X_train = train_processed.drop(columns=[\"price\", \"log_price\"], errors='ignore')\n",
    "y_train = train_processed[\"log_price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4b. Preprocess test data (using fitted pipeline) ===\n",
    "test_df = X_test_raw.copy()\n",
    "test_df[\"price\"] = y_test_raw  # For consistency\n",
    "test_processed = pipeline.transform(test_df)\n",
    "X_test = test_processed.drop(columns=[\"price\", \"log_price\"], errors='ignore')\n",
    "y_test = test_processed[\"log_price\"] if \"log_price\" in test_processed.columns else y_test_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 5. Train basic XGBoost model ===\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "    \"subsample\": [0.7, 0.9, 1.0],\n",
    "    \"colsample_bytree\": [0.7, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "base_model = XGBRegressor(random_state=42, n_jobs=-1)\n",
    "grid_search = GridSearchCV(base_model, param_grid, cv=3, scoring=\"neg_root_mean_squared_error\", verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_model = grid_search.best_estimator_\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6. Predict and evaluate ===\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"XGBoost RMSE (log-target): {rmse:.2f}\")\n",
    "print(f\"XGBoost R2 Score: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 7. Save model ===\n",
    "import joblib\n",
    "joblib.dump(xgb_model, \"../models/xgboost_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 8. Generate predictions for stacking ===\n",
    "# Note: This generates predictions on full training set, not OOF\n",
    "# For proper OOF predictions, use the oof_xgboost.py script\n",
    "full_train_processed = pipeline.fit_transform(df)\n",
    "X_full = full_train_processed.drop(columns=[\"price\", \"log_price\"], errors='ignore')\n",
    "train_preds = xgb_model.predict(X_full)\n",
    "pd.DataFrame({\n",
    "    \"xgb_oof_pred\": train_preds\n",
    "}).to_csv(\"../results/xgb_oof_train_preds.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 9. Load and preprocess test data ===\n",
    "test_df = load_test_data()\n",
    "# Use the same pipeline that was fitted on training data\n",
    "test_clean = pipeline.transform(test_df)\n",
    "\n",
    "# === 10. Predict and save submission ===\n",
    "test_preds = np.expm1(xgb_model.predict(test_clean))  # Convert log(price) back\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": test_df[\"ID\"],\n",
    "    \"Actual\": test_preds\n",
    "})\n",
    "submission.to_csv(\"../results/xgb_test_preds.csv\", index=False)\n",
    "print(\"âœ… XGBoost submission saved to: ../results/xgb_test_preds.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
